---
title: "DataSci 306 Final Project"
author: "DataSci 306 Instructional Team"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(stringr)
library(ggplot2)
```

## Investigating the Internet Movie Database (IMDB)

The [Internet Movie Database (IMDb)]() contains information on millions of movies and television programs. They offer several [non-commercial use datasets](https://developer.imdb.com/non-commercial-datasets/) (documentation link). For this project we will analyze a **sample** of 100,000 titles from the IMDBb. 


## Part I: Preprocessing

* [Edit your `.gitignore` file](https://docs.github.com/en/get-started/getting-started-with-git/ignoring-files) to ignore all files with the `.rda` extension. (Add and commit)
* Create a new file in the `data/` directory called "Preprocessing.Rmd". The remaining instructions in this section are to be completed in that file.
* Write a function that will load a table from the IMDb files in the `data/` directory.
  * The function should take the file name (without the ".csv.gz" portion) as an argument
  * The function should load the appropriate `.csv.gz` file.
  * Make sure that all "\\N" values (which IMDB uses to indicate missing values) are turned into proper NA values in R
  * The function should return the table.
* For each of the `.csv.gz` files, use your function to load the table, then save it into a variable (e.g. `name_basics <- preprocess("name_basics")`) and use the `write_rds` function (e.g., `write_rds(name_basics, "name_basics.rda")`.
* Run the function on all of the `*_sample.csv.gz` files to created processed `.rda` files.
* In your other files, you can load these using the `TABLE <- read_rds("data/FILENAME.rda")` function.

## Part II: EDA of individual tables

```{r}
name_basics <- read_rds("data/name_basics_sample.rda")
title_basics <- read_rds("data/title_basics_sample.rda")
title_principals <- read_rds("data/title_principals_sample.rda")
title_ratings <- read_rds("data/title_ratings_sample.rda")
```

```{r}
#name_basics
summary(name_basics$birthYear)
summary(name_basics$deathYear)

name_basics$primaryProfession <- as.factor(name_basics$primaryProfession)
summary(name_basics$primaryProfession)

name_basics %>% summarise(unique_primaryName = n_distinct(primaryName))

name_basics$numKnownForTitles <- sapply(str_split(name_basics$knownForTitles, ","), length)
summary(as.factor(name_basics$numKnownForTitles))

current_year <- 2025
name_basics <- name_basics %>%
  mutate(
    age = ifelse(is.na(deathYear), current_year - birthYear, deathYear - birthYear),
    is_alive = ifelse(is.na(deathYear), "Living", "Deceased"))

name_basics %>%
  filter(str_detect(primaryName, "^(Tom|Thomas|Thom|Tomas)\\b")) %>%
  count()

# Plot: Distribution of Birth Years
ggplot(name_basics, aes(x = birthYear)) +
  geom_histogram(bins = 50, fill = "blue", color = "black") +
  labs(title = "Distribution of Birth Years", x = "Birth Year", y = "Frequency")

# Plot: Age Distribution of Deceased Cast Member
ggplot(name_basics %>% filter(is_alive == "Deceased"), aes(x = age)) +
  geom_histogram(fill = "blue", bins = 30) +
  theme_minimal() +
  labs(title = "Age Distribution of Deceased Cast Members")

# Plot: Age Distribution of Living Cast Member
ggplot(name_basics %>% filter(is_alive == "Living"), aes(x = age)) +
  geom_histogram(fill = "green", bins = 30) +
  theme_minimal() +
  labs(title = "Age Distribution of Living Cast Members")

# Plot: Number of Titles Known for
ggplot(name_basics, aes(x = numKnownForTitles)) +
  geom_bar(fill = "green") +
  labs(title = "Number of Titles Known for Each Person", x = "Number of Titles", y = "Frequency")
```

```{r}
#title_basics
summary(title_basics$startYear)
summary(title_basics$endYear)
summary(title_basics$runtimeMinutes)

title_basics$titleType <- as.factor(title_basics$titleType)
title_basics$genres <- as.factor(title_basics$genres)

summary(title_basics$titleType)
summary(title_basics$genres)

runtime_by_type <- title_basics %>%
  group_by(titleType) %>%
  summarise(
    mean_runtime = mean(runtimeMinutes, na.rm = TRUE),
    median_runtime = median(runtimeMinutes, na.rm = TRUE),
    count = n()
  )
runtime_by_type

runtime_by_genre <- title_basics %>%
  group_by(genres) %>%
  summarise(
    mean_runtime = mean(runtimeMinutes, na.rm = TRUE),
    median_runtime = median(runtimeMinutes, na.rm = TRUE),
    count = n()
  ) %>%
  arrange(desc(count))
runtime_by_genre

num_diff_titles <- title_basics %>%
  filter(primaryTitle != originalTitle) %>%
  nrow()

is_alliterative <- function(title) {
  words <- unlist(str_split(tolower(title), "\\s+")) # Convert to lower case for uniformity
  first_letters <- substr(words, 1, 1)
  return(all(first_letters == first_letters[1]))
}

title_basics$is_alliterative <- sapply(title_basics$primaryTitle, is_alliterative)
alliterative_count <- sum(title_basics$is_alliterative, na.rm = TRUE)

#Plot: Distribution of RunTime Minutes by Title Type
ggplot(title_basics, aes(x = runtimeMinutes, fill = titleType)) +
  geom_histogram(bins = 50, position = "stack") +
  labs(title = "Distribution of Runtime Minutes by Title Type", x = "Runtime Minutes")

#Plot: Conditional Distributions of Release Year 
title_basics <- title_basics %>%
  mutate(different_name = primaryTitle != originalTitle)

ggplot(title_basics, aes(x = startYear, fill = different_name)) +
  geom_histogram(binwidth = 1, position = "dodge") +
  facet_wrap(~different_name) +
  labs(title = "Distribution of Release Years for Titles with Different vs. Same Name", 
       x = "Start Year", 
       fill = "Different Name?")

#Plot: As a Density Plot
ggplot(title_basics, aes(x = startYear, fill = different_name, color = different_name)) +
  geom_density(alpha = 0.4, adjust = 1.5) +
  labs(title = "Density of Release Years for Titles with Different vs. Same Name",
       x = "Start Year",
       y = "Density",
       fill = "Different Name?",
       color = "Different Name?") +
  scale_fill_manual(values = c("steelblue", "coral")) +
  scale_color_manual(values = c("steelblue", "coral"))
```
**Based on both the histogram and density plot shown, we observe that titles with a different primary and original title are mostly released after 1990, with a noticable peak in 2010. Titles with the same name are distributed more broadly across the years with a sharp increase after 1990. This trend suggests that renaming title, due to whatever reason, has become a more common practice in modern entertainment.**

```{r}
#title_principals
summary(title_principals)

summary(title_principals$ordering)

title_principals$category <- as.factor(title_principals$category)
title_principals$job <- as.factor(title_principals$job)

summary(title_principals$category)
summary(title_principals$job)

title_principals %>%
  count(category) %>%
  arrange(desc(n))

#Plot: Count of Principals by Category
ggplot(title_principals, aes(x = category)) +
  geom_bar(fill = "steelblue") +
  coord_flip() +
  labs(title = "Principals by Category", x = "Category", y = "Count") +
  theme_minimal()
```
```{r}
summary(title_ratings)
summary(title_ratings$averageRating)
summary(title_ratings$numVotes)

title_ratings$ratingCategory <- cut(
  title_ratings$averageRating,
  breaks = c(0, 5, 8, 10),
  labels = c("Low", "Medium", "High")
)
table(title_ratings$ratingCategory)

avg_votes_by_rating <- title_ratings %>%
  group_by(ratingCategory) %>%
  summarise(mean_votes = mean(numVotes, na.rm = TRUE), .groups = 'drop')

avg_votes_by_rating

# Plot: Distribution of Average Ratings
ggplot(title_ratings, aes(x = averageRating, fill = ratingCategory)) +
  geom_histogram(bins = 30, alpha = 0.6) +
  labs(title = "Distribution of Average Ratings", x = "Average Rating") +
  theme_minimal()

# Plot: Average number of votes by rating category
ggplot(avg_votes_by_rating, aes(x = ratingCategory, y = mean_votes, fill = ratingCategory)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Average Number of Votes by Rating Category", x = "Rating Category", y = "Average Number of Votes")

#Plot: A scatterplot of averageRating vs numVotes
ggplot(title_ratings, aes(x = averageRating, y = numVotes)) +
  geom_point(alpha = 0.5) +
  scale_y_log10() +
  labs(title = "Votes vs. Average Rating",
       x = "Average Rating",
       y = "Number of Votes (log scale)")
```




* For each of the 4 tables, perform basic exploratory data analysis. Report the following information:
  * For each quantitative column, provide some summary statistics
  * For any character columns, decided if they are actually representing factors/categorical data with a moderate number of columns. If so report the distributions for these variables.
  * Provide a plot for each table. Across all of the plots, try to show off the most possible different ggplot features (`geoms_` functions, `stat_` functions, coordinate systems, facets, use of several variables, annotations)
* For the `titles_basics` table
  * use two different variables to group and explore how `runtimeMinutes` varies for these different groups. Produce appropriate summaries.
  * How many titles are known for name that is different than the original release name?
  * Graph the conditional distributions of release year based on the previous results. Comment on any trends you observe.
* For the ratings, use the `cut` function to break the data into three groups based on the average ratings. Are higher rated titles rated more often or less often than lower rated titles? 
* For the names table, 
  * Count the number of titles each person is known for and plot this distribution.
  * investigate the age of cast members
      * Group the data into living and deceased cast members. 
      * For deceased cast members, provide a graph that shows the distribution of ages.
      * Do the same for living cast members.
* Find all the actors with first names "Tom", "Thomas", "Thom" or "Tomas". How many are there?
* How many titles use alliteration (i.e., all words in the title start with the same letter)?

**There are 4331 actors with the first name "Tom", "Thomas", "Thom" or "Tomas"**
**There are 7244 titles that are known for name that is different than the original release name.**
**There are 16549 titles that use alliteration.**

## Part III: Pivoting

* Create a new version of the `titles_basics` table that has one row for each title-genre combination. See the `separate_rows` function for a useful too here.
* Using that table, create a line plot of the count different genres over time (you may limit this to the most common genres if you wish).
* Use the `model.matrix` function in the following way: `model.matrix(yourtalltable, ~ genre - 1)` to create a wide table with one column for each genre. Use this table to find the most common pair of genres (hint: use the `cor` function or produce facet plots)

```{r}
library(tidyverse)

# ──────────────────────────────────────
# 1. Build a “long” table: one row per (title, genre)
# ──────────────────────────────────────
titles_genre_long <- title_basics %>% 
  filter(genres != "\\N") %>%           # drop missing genre strings
  separate_rows(genres, sep = ",")      # split "Drama,Romance" → two rows

# ──────────────────────────────────────
# 2. Line plot of genre counts over time (top 8 genres)
# ──────────────────────────────────────
genre_year_counts <- titles_genre_long %>% 
  count(startYear, genres, name = "n")

top_genres <- titles_genre_long %>%               # the 8 most frequent genres
  count(genres, sort = TRUE) %>% 
  slice_head(n = 8) %>% 
  pull(genres)

ggplot(filter(genre_year_counts, genres %in% top_genres),
       aes(startYear, n, colour = genres)) +
  geom_line(linewidth = 1) +
  labs(title = "Title counts by genre over time",
       x = "Release year",
       y = "Number of titles",
       colour = "Genre") +
  scale_x_continuous(breaks = seq(1920, 2025, 10)) +
  theme_minimal()

# ──────────────────────────────────────
# 3. Create a 0/1 dummy (wide) table for genres
# ──────────────────────────────────────
genre_dummy <- titles_genre_long %>% 
  distinct(tconst, genres) %>%          # ensure one row per (title, genre)
  mutate(flag = 1L) %>% 
  pivot_wider(
    names_from   = genres,
    values_from  = flag,
    values_fill  = 0L,
    values_fn    = max,                 # combine duplicated rows safely
    names_repair = "minimal"
  )

# ──────────────────────────────────────
# 4. Most common genre pairs (top 10)  –  FIXED
# ──────────────────────────────────────
G_mat  <- as.matrix(select(genre_dummy, -tconst))   # numeric 0/1 matrix
co_mat <- crossprod(G_mat)                          # genre × genre co-occurrence

pair_counts <- as.data.frame(as.table(co_mat),     # Var1 / Var2 are factors
                             stringsAsFactors = FALSE) %>%  # <-- make them character
  filter(Var1 != Var2) %>%                         # drop the diagonal
  arrange(desc(Freq)) %>% 
  slice_head(n = 10) %>% 
  transmute(
    genre_pair = paste(Var1, Var2, sep = " & "),
    count      = Freq
  )

print(pair_counts)

```




## Part IV: Joining Tables

* Join the table with one title-genre per row from the previous section with the ratings table.
  * What is the highest rated genre? What is the lowest rated genre?
  * Using stacked bar charts, investigate the proportions of different genres over time. Are any incresing or decreasing? Use factor functions to help make the plots easier to read.
* Join the `title_basics` with the ratings table. Have the number of ratings changed over time (based on release year)? Display graphically but also answer with numerical results.
* Join the names with the ratings and the principals table. 
  * Group by individual people, find the top ten people based on the median rating of the titles they appear in.
  * Find the proportions of genres for the the titles that include the top 10 rated principals.
  * Graph ratings against years. What trends do you see?
* Create a table with one row for each person in the `name_basics` table and title they are known for. Join this to the ratings table to get the ratings of the "known for" films. Find the person (or people) who have the highest median known for rating.
* 
```{r}

library(tidyverse)

#──────────────────────────────────────
# A. Rating statistics by genre
#──────────────────────────────────────
genre_ratings <- titles_genre_long %>% 
  inner_join(title_ratings, by = "tconst")

genre_summary <- genre_ratings %>% 
  group_by(genres) %>% 
  summarise(
    avg_rating = mean(averageRating, na.rm = TRUE),
    med_rating = median(averageRating, na.rm = TRUE),
    n_titles   = n(),
    .groups    = "drop"
  )

highest_rated <- genre_summary %>% slice_max(avg_rating, n = 1)
lowest_rated  <- genre_summary %>% slice_min(avg_rating, n = 1)

# show in document
highest_rated
lowest_rated

#──────────────────────────────────────
# Stacked bar: genre proportions by decade
#──────────────────────────────────────
genre_ratings %>% 
  mutate(decade = cut(startYear,
                      breaks = seq(1920, 2030, 10),
                      right  = FALSE,
                      labels = paste0(seq(1920, 2020, 10), "s"))) %>% 
  count(decade, genres) %>% 
  group_by(decade) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup() %>% 
  ggplot(aes(decade, prop, fill = fct_lump(genres, 10))) +
  geom_col() +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "Genre proportions by decade",
       x = "Decade",
       y = "Proportion",
       fill = "Genre (top 9 + Other)") +
  theme_minimal()
```
```{r}

cat(
  "Highest-rated genre:", highest_rated$genres,
  "-- average rating =", round(highest_rated$avg_rating, 2), "\n",
  "Lowest-rated genre:",  lowest_rated$genres,
  "-- average rating =", round(lowest_rated$avg_rating, 2)
)

```

```{r}
#──────────────────────────────────────
# B. Votes vs. release year
#──────────────────────────────────────
title_rt <- title_basics %>% 
  inner_join(title_ratings, by = "tconst")

votes_by_year <- title_rt %>% 
  group_by(startYear) %>% 
  summarise(
    mean_votes   = mean(numVotes),
    median_votes = median(numVotes),
    n_titles     = n(),
    .groups      = "drop"
  )

ggplot(votes_by_year, aes(startYear, mean_votes)) +
  geom_line() +
  labs(title = "Average number of votes vs. release year",
       x = "Release year",
       y = "Mean numVotes") +
  theme_minimal()
```
```{r}
# change from first to last year with data
v_change <- votes_by_year %>%
  filter(!is.na(mean_votes)) %>%
  summarise(
    first_year = startYear[which.min(startYear)],
    last_year  = startYear[which.max(startYear)],
    delta      = mean_votes[which.max(startYear)] -
                 mean_votes[which.min(startYear)]
  )

cat(
  "Between", v_change$first_year, "and", v_change$last_year, 
  "the average number of votes per title changed by",
  round(v_change$delta, 1), 
  ifelse(v_change$delta > 0, "(increase).", "(decrease).")
)
```

```{r}
#──────────────────────────────────────
# C. Top-10 principals by median rating
#──────────────────────────────────────
# ── 1. Build people_ratings (fast, only required cols) ────────────────
people_ratings <- title_principals %>% 
  select(tconst, nconst) %>% 
  inner_join(title_ratings %>% select(tconst, averageRating),  # ratings
             by = "tconst") %>% 
  inner_join(title_basics  %>% select(tconst, startYear),      # year
             by = "tconst", relationship = "many-to-many") %>% 
  inner_join(name_basics   %>% select(nconst, primaryName),    # names
             by = "nconst")

# 2. Top-10 principals by median rating (≥ 3 titles)
top10_people <- people_ratings %>% 
  group_by(nconst, primaryName) %>% 
  summarise(
    med_rating = median(averageRating),
    n_titles   = n(),
    .groups    = "drop"
  ) %>% 
  filter(n_titles >= 3) %>% 
  slice_max(med_rating, n = 10)

top10_people   # table output

# 3. Genre mix for the top-10 principals
top10_mix <- people_ratings %>% 
  semi_join(top10_people, by = "nconst") %>% 
  inner_join(titles_genre_long, by = "tconst", relationship = "many-to-many") %>% 
  count(primaryName, genres) %>% 
  group_by(primaryName) %>% 
  mutate(prop = n / sum(n)) %>% 
  ungroup()

top5_mix <- top10_mix %>% 
  group_by(primaryName) %>% 
  slice_max(prop, n = 5) %>% 
  ungroup()

p_mix <- ggplot(top5_mix,
                aes(fct_reorder(genres, prop), prop, fill = genres)) +
  geom_col(width = 0.75, show.legend = FALSE) +
  geom_text(aes(label = scales::percent(prop, accuracy = 0.1)),
            hjust = -0.05, size = 3) +
  facet_wrap(~ primaryName, scales = "free_y", ncol = 2) +
  coord_flip(clip = "off") +
  scale_y_continuous(labels = scales::percent,
                     expand = expansion(mult = c(0, 0.15))) +
  labs(title = "Top 5 genres for each of the 10 highest-rated principals",
       x = NULL, y = "Proportion") +
  theme_minimal(base_size = 9) +
  theme(
    strip.text  = element_text(face = "bold", size = 10),
    axis.text.y = element_text(size = 8),
    plot.title  = element_text(face = "bold", size = 11,
                               margin = margin(b = 8))
  )

print(p_mix)

# ── 4. Rating trend over time (scatter + loess) ──────────────────────
rating_trend <- people_ratings %>% 
  group_by(startYear) %>% 
  summarise(mean_rating = mean(averageRating), .groups = "drop")

p_trend <- ggplot(rating_trend, aes(startYear, mean_rating)) +
  geom_line(linewidth = 1) +
  labs(title = "Average rating trend over time",
       x = "Release year", y = "Average rating") +
  theme_minimal()

print(p_trend)       # ensure plot appears
```

```{r}
#──────────────────────────────────────
# D. “Known-for” median ratings
#──────────────────────────────────────
knownfor_long <- name_basics %>% 
  select(nconst, knownForTitles) %>% 
  separate_rows(knownForTitles, sep = ",") %>% 
  rename(tconst = knownForTitles) %>% 
  inner_join(title_ratings, by = "tconst")

best_knownfor <- knownfor_long %>% 
  group_by(nconst) %>% 
  summarise(
    med_knownfor = median(averageRating),
    .groups      = "drop"
  ) %>% 
  slice_max(med_knownfor, n = 1) %>% 
  inner_join(name_basics, by = "nconst") %>% 
  select(primaryName, med_knownfor)

best_knownfor

```

## Part V: Profiling and Parallel Processing

* These are large data sets (and yet only a sample of the entire IMDb!), so it make sense spend some time improving our code.
* Pick one or more of the previous problems and profile the performance of that piece. Write up your findings. If you see any opportunities to improve performance, feel fee to implement than and share the results.


```{r}
library(bench)
library(future.apply)
library(profvis)
```

```{r}
# Profiling:
# choose the "known for" median rating calculation (from Part IV.D).

profvis({
  knownfor_long <- name_basics %>% 
    select(nconst, knownForTitles) %>% 
    separate_rows(knownForTitles, sep = ",") %>% 
    rename(tconst = knownForTitles) %>% 
    inner_join(title_ratings, by = "tconst") %>% 
    group_by(nconst) %>% 
    summarise(med_knownfor = median(averageRating), .groups = "drop")
})
```

> **Findings**: The `separate_rows()` function is a bottleneck, taking by far the most time and memory. This is because it has to expand many rows for people with multiple knownFor titles. The `median()` function took the second most time and memory, simply because the dataset becomes huge after `seaparate_rows()`; many rows exist per person. The `summarise()` and `group_by()` functions are efficient for this dataset. **One opportunity for improvement** could be speeding up `separate_rows()` by avoiding splitting empty or missing entries first. Implementing a simple filter step (removing empty or missing knownForTitles) before `separate_rows()` significantly reduced the time and memory usage during profiling.

```{r}
# Implementing improved known-for titles processing
knownfor_long_improved <- name_basics %>%
  select(nconst, knownForTitles) %>%
  filter(!is.na(knownForTitles), knownForTitles != "") %>%  # skip empty/missing titles
  separate_rows(knownForTitles, sep = ",") %>%
  rename(tconst = knownForTitles) %>%
  inner_join(title_ratings, by = "tconst")

# Group and compute median known-for rating
knownfor_medians_improved <- knownfor_long_improved %>%
  group_by(nconst) %>%
  summarise(med_knownfor = median(averageRating, na.rm = TRUE), .groups = "drop")


### Benchmark before and after ###
# Old method (unfiltered)
system.time({
  knownfor_long_old <- name_basics %>%
    select(nconst, knownForTitles) %>%
    separate_rows(knownForTitles, sep = ",") %>%
    rename(tconst = knownForTitles) %>%
    inner_join(title_ratings, by = "tconst") %>%
    group_by(nconst) %>%
    summarise(med_knownfor = median(averageRating, na.rm = TRUE), .groups = "drop")
})

# Improved method (filter first)
system.time({
  knownfor_long_improved <- name_basics %>%
    select(nconst, knownForTitles) %>%
    filter(!is.na(knownForTitles), knownForTitles != "") %>%
    separate_rows(knownForTitles, sep = ",") %>%
    rename(tconst = knownForTitles) %>%
    inner_join(title_ratings, by = "tconst") %>%
    group_by(nconst) %>%
    summarise(med_knownfor = median(averageRating, na.rm = TRUE), .groups = "drop")
})


```

* Select a previous computation that could be improved using parallelization and implement a parallelization solution. Using `system.time` show that parallelization improves performance.



```{r}
## Parallelization, use system.time to show improvement

library(dplyr)
library(future.apply)
plan(multisession)

# Do filtering/joining
knownfor_long <- name_basics %>%
  select(nconst, knownForTitles) %>%
  filter(!is.na(knownForTitles), knownForTitles != "") %>%
  separate_rows(knownForTitles, sep = ",") %>%
  rename(tconst = knownForTitles) %>%
  inner_join(title_ratings, by = "tconst")

# Original version (for timing)
original_time <- system.time({
  knownfor_medians_original <- knownfor_long %>%
    group_by(nconst) %>%
    summarise(med_knownfor = median(averageRating), .groups = "drop")
})

print(original_time)

##### Parallel version #####

# Split into list by nconst (each person separately)
knownfor_groups <- split(knownfor_long$averageRating, knownfor_long$nconst)

# Parallel apply median
parallel_time <- system.time({
  median_list <- future_lapply(knownfor_groups, median, na.rm = TRUE)
  
  # Turn back into a dataframe
  knownfor_medians_parallel <- tibble(
    nconst = names(median_list),
    med_knownfor = unlist(median_list)
  )
})

print(parallel_time)

# Confirm matching results
all.equal(
  knownfor_medians_original %>% arrange(nconst),
  knownfor_medians_parallel %>% arrange(nconst),
  check.attributes = FALSE # ignore row name attributes (check values)
)
```
> **Findings:** We parallelized the computation of median known-for ratings by splitting the data into groups by nconst and applying future_lapply(). Parallelization improved the overall runtime compared to the serial version. The parallel and serial outputs matched exactly (values were identical). Therefore, parallel processing was effective for this heavier task.

* One task we performed involved counting items in strings separated by commas. Propose two different functions that could perform this taks. Compare them using bench marking. Which version would you recommend?


```{r}
# Proposal 1: split the string at commas, count the number of parts (length)
count_split <- function(x) {
  length(str_split(x, ",")[[1]])
}

# Proposal 2: count how many commas there are, add 1
count_commas <- function(x) {
  if (is.na(x) || x == "") return(0)
  str_count(x, ",") + 1
}

### Benchmark ###
library(stringr)

example_vec <- name_basics$knownForTitles

bench::mark(
  sapply(example_vec, count_split),
  sapply(example_vec, count_commas),
  check = FALSE
)

```

> We compared two methods of counting "known-for" titles using the knownForTitles field from the name_basics table. Using real data, benchmarking showed that counting commas (str_count() + 1) was significantly faster compared to splitting the strings and counting parts. Therefore, we recommend using the **comma counting** method for efficiency, especially on large datasets.


## Part VI: Shiny Applications

### Application 1

Using results from the previous section, create a shiny application that allows users to interact with the with the IMDb data. The application should use both interactive graphs and at least 3 widgets.

*partVI_app1.R**

### Application 2

In the principals table, there is a `category` column. Use this column as a primary filter to allow users to then select specific job categories. After select the specific job categories, display information from another table.

*partVI_app2.R**

## Extra Credit: 6 Degrees of Kevin Bacon

Create an app to allow users to play [Six Degrees of Kevin Bacon](https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon#:~:text=Six%20Degrees%20of%20Kevin%20Bacon%20or%20Bacon's%20Law%20is%20a,ultimately%20leads%20to%20prolific%20American).

Create a Shiny application where a person can type the primary title of movie or TV show. Then have app show all the people who had a role in the show. Let the user select a person in that cast and show all other people who have been in a title with that person. Repeat up to 6 times. If "Kevin Bacon" (`nconst == 'nm0000102'`) ever appears in the list, let the player know they have won! If they click more than 6 times, let them know they have lost.

*6dkevinb.R**


